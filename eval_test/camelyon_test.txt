import os
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from  torch.autograd import Variable
import time

from  basic.eval_test import BasicTest
from  basic.utils import image_transform
from  basic.data import camelyon_data
from  basic.utils import logs
from  basic.utils import counter
from  basic.utils import accuracy
from  basic.model import camelyon_models

import pdb
import json


class Test(BasicTest):
    """模型性能的test部份
    内部不加载模型，只通过load model处理"""

    def __init__(self, config):
        super(Test, self).__init__()
        self.config = config
        save_folder = os.path.join(self.config.get_config('base', 'save_folder'),
                                   self.config.get_config('base', 'last_run_date'))
        self.log = logs.Log(os.path.join(save_folder, "log.txt"))
        # dataloader
        self.test_loader = None
        # test params
        self.best_epoch = 0
        self.best_acc = 0
        self.after_model_output = getattr(camelyon_models, 'after_model_output')

    def cfg(self, name):
        """获取配置简易方式"""
        return self.config.get_config('test', name)

    def load_data(self):
        test_transform = image_transform.get_test_transforms()
        test_dataset = camelyon_data.TestDataset(self.config.get_config('base', 'test_list'),
                                                 transform=test_transform,
                                                 tif_folder=self.config.get_config('base', 'test_tif_folder'),
                                                 patch_size=self.config.get_config('base', 'patch_size'))
        # 这里为了减少openslide的内存消耗，采用shuffle=False的方式，按顺序取数据
        return torch.utils.data.DataLoader(test_dataset, batch_size=self.cfg('batch_size'),
                                           shuffle=False, num_workers=self.cfg('num_workers'))

    def test(self, _model, epoch, hard_mining_times, save_helper):
        _model.eval()

        time_counter = counter.Counter()
        time_counter.addval(time.time(), key='test epoch start')
        # 1.生成单张的slide列表，按slide遍历，可以得到中间结果
        # 1.1 读取数据
        print('start loading test list')
        load_time = time.time()
        _f = open(self.config.get_config('base', 'test_list'), 'r')
        content = _f.read()
        print('read txt from  disk complete!', time.time() - load_time)
        patch_dict = json.loads(content)
        print('loading test json list complete! time:%0.4f  total patch:%d' % ((time.time() - load_time), len(patch_dict)))
        # 1.1 将数据按照slide的维度划分, {slide0:{xxx:0}}
        slide_patch_dict = {}
        print('start split patch list')
        patch_time = time.time()
        for patch_name in patch_dict.keys():
            slide_name = patch_name.split('.tif_')[0] + '.tif'
            if slide_name in slide_patch_dict.keys():
                slide_patch_dict[slide_name][patch_name] = patch_dict[patch_name]
            else:
                slide_patch_dict[slide_name] = {}
                slide_patch_dict[slide_name][patch_name] = patch_dict[patch_name]
        print('split patch list complete')
        for k in slide_patch_dict.keys():
            print('slide:%s patch:%d' % (k, len(slide_patch_dict[k])))

        # 2.以slide_name为维度去test
        slide_name_list = list(slide_patch_dict.keys())
        slide_name_list.sort()
        
        start_index = self.config.get_config('test', 'start_index')
        end_index = self.config.get_config('test', 'end_index')
        end_index = end_index if end_index!=0 else len(slide_name_list)
        for slide_index in range(start_index, end_index):
            slide_name = slide_name_list[slide_index]
            test_transform = image_transform.get_test_transforms()
            test_dataset = camelyon_data.TestDataset(slide_name, slide_patch_dict[slide_name],
                                                     transform=test_transform,
                                                     tif_folder=self.config.get_config('base', 'test_tif_folder'),
                                                     patch_size=self.config.get_config('base', 'patch_size'))
            dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=self.cfg('batch_size'),
                                                     shuffle=False, num_workers=self.cfg('num_workers'))

            # 2.1 遍历该slide的patch
            acc = {'avg_counter_total': counter.Counter(), 'avg_counter_pos': counter.Counter(),
               'avg_counter_neg': counter.Counter(),
               'avg_counter': counter.Counter(), 'epoch_acc_image': []}
            for i, data in enumerate(dataloader, 0):
                test_input, batch_labels, path_list = data
                if torch.cuda.is_available():
                    test_input = Variable(test_input.type(torch.cuda.FloatTensor))
                else:
                    test_input = Variable(test_input.type(torch.FloatTensor))
                #             test_input = Variable(test_input.type(torch.FloatTensor))
                test_output = _model(test_input)
                
                # google net在test时没用使用aux
                test_output = self.after_model_output(test_output, self.config)
                test_output = test_output.cpu()
                batch_labels = Variable(batch_labels.type(torch.FloatTensor))

                # 结果处理，计算acc
                #             top1 = accuracy.topk(test_output.cpu(), batch_labels, top=(1,))
                #             acc['avg_counter'].addval(top1[0], len(test_output))
                testoutput=test_output.squeeze()
                train_output=train_output[:,1]>train_output[:,0]
                acc_batch_total, acc_batch_pos, acc_batch_neg = accuracy.acc_binary_class(test_output.cpu(), batch_labels, 0.5)
                acc_batch = acc_batch_total
                acc['avg_counter_total'].addval(acc_batch_total)
                acc['avg_counter_pos'].addval(acc_batch_pos)
                acc['avg_counter_neg'].addval(acc_batch_neg)
                acc['avg_counter'].addval(acc_batch)

                # acc_image_list = accuracy.topk_with_class(test_output.cpu(), batch_labels, path_list, topk=1)
                accuracy.handle_binary_classification(test_output.cpu(), batch_labels, path_list, acc['epoch_acc_image'], 0.8)
                time_counter.addval(time.time())
                self.log.info(
                    'test epoch slide:%d/%d %s,batch iter:%d/%d,acc-iter/avg:[%.2f/%.2f]-[%.2f--%.2f--%.2f], time consume:%.2f s' % (
                        epoch, self.config.get_config('train', 'total_epoch'), slide_name, i, len(dataloader),
                        acc_batch,
                        acc['avg_counter'].avg,
                        acc['avg_counter_total'].avg, acc['avg_counter_pos'].avg, acc['avg_counter_neg'].avg,
                        time_counter.interval()), end='\r')
                pass

            # 2.2 保存好输出的结果，不要加到循环日志中去
            save_helper.save_epoch_pred(acc['epoch_acc_image'],
                                        'test_hardmine_%d_epoch_%d_slide_%s.txt' % (
                                        hard_mining_times, epoch, slide_name))
            save_helper.save_epoch_model(hard_mining_times, epoch, 'test', acc, None, _model)

            time_counter.addval(time.time(), key='test epoch end')
            self.log.info(
                ('\ntest epoch slide time consume:%.2f s' % (time_counter.key_interval(key_ed='test epoch end',
                                                                                       key_st='test epoch start'))))
            test_dataset.slide.close()

            
            
            
